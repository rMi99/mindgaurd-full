# scripts/train_model.py (with K-Fold Cross-Validation)

import numpy as np
import pandas as pd
import torch
from torch import nn
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
from dotenv import load_dotenv

from app.models.model import RiskModel

# ... (load your data and scaler as before) ...

# ─── K-FOLD CROSS-VALIDATION SETUP ──────────────────────────────────────────
k_folds = 5
kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)

# To store the results
fold_results = []

for fold, (train_ids, val_ids) in enumerate(kfold.split(X_scaled)):
    print(f'FOLD {fold+1}/{k_folds}')

    # Split data for this fold
    X_train, X_val = X_scaled[train_ids], X_scaled[val_ids]
    y_train, y_val = y[train_ids], y[val_ids]

    train_x = torch.tensor(X_train, dtype=torch.float32)
    train_y = torch.tensor(y_train, dtype=torch.long)
    val_x   = torch.tensor(X_val,   dtype=torch.float32)
    val_y   = torch.tensor(y_val,   dtype=torch.long)

    # Re-initialize the model, optimizer, etc. for each fold
    input_dim  = train_x.shape[1]
    num_classes = len(torch.unique(train_y))
    model      = RiskModel(input_dim, hidden_dim=64, output_dim=num_classes)
    criterion  = nn.CrossEntropyLoss()
    optimizer  = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
    # ... (your training loop for this fold) ...

    # Evaluation for this fold
    model.eval()
    with torch.no_grad():
        preds = model(val_x).argmax(dim=1)

    acc = accuracy_score(val_y, preds)
    fold_results.append(acc)
    print(f"Accuracy for fold {fold+1}: {acc * 100:.2f}%\n")

print(f"Average accuracy over {k_folds} folds: {np.mean(fold_results) * 100:.2f}%")
print(f"Standard deviation: {np.std(fold_results) * 100:.2f}%")

# ... (After finding the best hyperparameters, you can train on all data and save the model) ...