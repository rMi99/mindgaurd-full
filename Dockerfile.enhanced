# Enhanced Docker Configuration for Adaptive AI System
# Multi-stage build for optimized production deployment

# =============================================================================
# BACKEND DOCKERFILE - Enhanced with AI Dependencies
# =============================================================================

FROM python:3.12-slim as backend-base

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies for AI/ML libraries
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    pkg-config \
    libopencv-dev \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgcc-s1 \
    libstdc++6 \
    libgfortran5 \
    libblas3 \
    liblapack3 \
    libatlas-base-dev \
    gfortran \
    wget \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app directory
WORKDIR /app

# Copy requirements first for better caching
COPY backend/requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Install additional AI/ML dependencies
RUN pip install --no-cache-dir \
    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu \
    tensorflow \
    scikit-learn \
    opencv-python \
    mediapipe \
    dlib \
    face-recognition \
    deepface \
    websockets \
    fastapi[all] \
    uvicorn[standard]

# Copy application code
COPY backend/ .

# Create necessary directories
RUN mkdir -p /app/data/models /app/logs /app/temp

# Set permissions
RUN chmod +x /app/scripts/*.py

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Development stage
FROM backend-base as backend-dev

# Install development dependencies
RUN pip install --no-cache-dir \
    pytest \
    pytest-asyncio \
    black \
    flake8 \
    mypy \
    jupyter \
    ipython

# Run in development mode
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

# Production stage
FROM backend-base as backend-prod

# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app
USER appuser

# Run in production mode
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]

# =============================================================================
# FRONTEND DOCKERFILE - Enhanced with WebSocket Support
# =============================================================================

FROM node:18-alpine as frontend-base

# Set working directory
WORKDIR /app

# Copy package files
COPY frontend/package*.json ./
COPY frontend/pnpm-lock.yaml ./

# Install dependencies
RUN npm install -g pnpm && pnpm install --frozen-lockfile

# Copy source code
COPY frontend/ .

# Development stage
FROM frontend-base as frontend-dev

# Expose port
EXPOSE 3000

# Run development server
CMD ["pnpm", "dev"]

# Production build stage
FROM frontend-base as frontend-build

# Build the application
RUN pnpm build

# Production stage
FROM nginx:alpine as frontend-prod

# Copy built application
COPY --from=frontend-build /app/.next/standalone ./
COPY --from=frontend-build /app/.next/static ./.next/static
COPY --from=frontend-build /app/public ./public

# Copy custom nginx config
COPY nginx/nginx.conf /etc/nginx/nginx.conf

# Expose port
EXPOSE 80

# Start nginx
CMD ["nginx", "-g", "daemon off;"]

# =============================================================================
# NGINX CONFIGURATION
# =============================================================================

# Enhanced nginx.conf for AI system
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

    # Rate limiting for API endpoints
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=websocket:10m rate=5r/s;

    # WebSocket proxy settings
    map $http_upgrade $connection_upgrade {
        default upgrade;
        '' close;
    }

    # Backend upstream
    upstream backend {
        server backend:8000;
    }

    # Frontend upstream
    upstream frontend {
        server frontend:3000;
    }

    server {
        listen 80;
        server_name localhost;

        # Security headers
        add_header X-Frame-Options DENY;
        add_header X-Content-Type-Options nosniff;
        add_header X-XSS-Protection "1; mode=block";
        add_header Referrer-Policy "strict-origin-when-cross-origin";

        # API routes with rate limiting
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # Timeout settings for AI processing
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # WebSocket routes
        location /ws/ {
            limit_req zone=websocket burst=10 nodelay;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            
            # WebSocket specific timeouts
            proxy_read_timeout 86400s;
            proxy_send_timeout 86400s;
        }

        # Health check endpoint
        location /health {
            proxy_pass http://backend;
            access_log off;
        }

        # Frontend routes
        location / {
            proxy_pass http://frontend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Static files caching
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
            proxy_pass http://frontend;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}

# =============================================================================
# DOCKER COMPOSE - Enhanced Configuration
# =============================================================================

version: '3.8'

services:
  # Enhanced Backend Service
  backend:
    build:
      context: .
      dockerfile: Dockerfile.enhanced
      target: backend-prod
    container_name: mindguard-backend
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - MONGODB_URL=mongodb://mongo:27017/mindguard
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./backend/data:/app/data
      - ./backend/logs:/app/logs
      - ./backend/temp:/app/temp
    ports:
      - "8000:8000"
    depends_on:
      - mongo
      - redis
    networks:
      - mindguard-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Enhanced Frontend Service
  frontend:
    build:
      context: .
      dockerfile: Dockerfile.enhanced
      target: frontend-prod
    container_name: mindguard-frontend
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_WS_URL=ws://localhost:8000
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - mindguard-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3

  # NGINX Reverse Proxy
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    container_name: mindguard-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend
      - frontend
    networks:
      - mindguard-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # MongoDB Database
  mongo:
    image: mongo:7.0
    container_name: mindguard-mongo
    restart: unless-stopped
    environment:
      - MONGO_INITDB_ROOT_USERNAME=admin
      - MONGO_INITDB_ROOT_PASSWORD=password123
      - MONGO_INITDB_DATABASE=mindguard
    volumes:
      - mongo_data:/data/db
      - ./backend/scripts/init_db.js:/docker-entrypoint-initdb.d/init_db.js
    ports:
      - "27017:27017"
    networks:
      - mindguard-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache
  redis:
    image: redis:7.2-alpine
    container_name: mindguard-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass password123
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - mindguard-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # AI Model Training Service (Optional)
  ai-trainer:
    build:
      context: .
      dockerfile: Dockerfile.training
    container_name: mindguard-ai-trainer
    restart: "no"
    environment:
      - PYTHONPATH=/app
      - MONGODB_URL=mongodb://mongo:27017/mindguard
    volumes:
      - ./backend/data:/app/data
      - ./backend/scripts:/app/scripts
    depends_on:
      - mongo
    networks:
      - mindguard-network
    profiles:
      - training

volumes:
  mongo_data:
    driver: local
  redis_data:
    driver: local

networks:
  mindguard-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# =============================================================================
# CI/CD PIPELINE CONFIGURATION
# =============================================================================

# GitHub Actions workflow
name: Enhanced AI System CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.12]
        node-version: [18]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Set up Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}

    - name: Install Python dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install pytest pytest-asyncio

    - name: Install Node.js dependencies
      run: |
        cd frontend
        npm install

    - name: Run Python tests
      run: |
        cd backend
        pytest tests/ -v

    - name: Run Node.js tests
      run: |
        cd frontend
        npm test

    - name: Run linting
      run: |
        cd backend
        flake8 app/
        black --check app/
        cd ../frontend
        npm run lint

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Backend image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.enhanced
        target: backend-prod
        push: true
        tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend:${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

    - name: Build and push Frontend image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile.enhanced
        target: frontend-prod
        push: true
        tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend:${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'

    steps:
    - uses: actions/checkout@v4

    - name: Deploy to AWS
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-east-1

    - name: Deploy to ECS
      run: |
        aws ecs update-service --cluster mindguard-cluster --service mindguard-service --force-new-deployment
